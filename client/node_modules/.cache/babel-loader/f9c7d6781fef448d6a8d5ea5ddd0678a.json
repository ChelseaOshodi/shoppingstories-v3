{"ast":null,"code":"'use strict';\n\nconst util = require('util');\n\nconst crypto = require('crypto');\n\nconst fs = require('@npmcli/fs');\n\nconst Minipass = require('minipass');\n\nconst path = require('path');\n\nconst ssri = require('ssri');\n\nconst uniqueFilename = require('unique-filename');\n\nconst contentPath = require('./content/path');\n\nconst fixOwner = require('./util/fix-owner');\n\nconst hashToSegments = require('./util/hash-to-segments');\n\nconst indexV = require('../package.json')['cache-version'].index;\n\nconst moveFile = require('@npmcli/move-file');\n\nconst _rimraf = require('rimraf');\n\nconst rimraf = util.promisify(_rimraf);\nrimraf.sync = _rimraf.sync;\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor(cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`);\n    this.code = 'ENOENT';\n    this.cache = cache;\n    this.key = key;\n  }\n\n};\nmodule.exports.compact = compact;\n\nasync function compact(cache, key, matchFn) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const bucket = bucketPath(cache, key);\n  const entries = await bucketEntries(bucket);\n  const newEntries = []; // we loop backwards because the bottom-most result is the newest\n  // since we add new entries with appendFile\n\n  for (let i = entries.length - 1; i >= 0; --i) {\n    const entry = entries[i]; // a null integrity could mean either a delete was appended\n    // or the user has simply stored an index that does not map\n    // to any content. we determine if the user wants to keep the\n    // null integrity based on the validateEntry function passed in options.\n    // if the integrity is null and no validateEntry is provided, we break\n    // as we consider the null integrity to be a deletion of everything\n    // that came before it.\n\n    if (entry.integrity === null && !opts.validateEntry) {\n      break;\n    } // if this entry is valid, and it is either the first entry or\n    // the newEntries array doesn't already include an entry that\n    // matches this one based on the provided matchFn, then we add\n    // it to the beginning of our list\n\n\n    if ((!opts.validateEntry || opts.validateEntry(entry) === true) && (newEntries.length === 0 || !newEntries.find(oldEntry => matchFn(oldEntry, entry)))) {\n      newEntries.unshift(entry);\n    }\n  }\n\n  const newIndex = '\\n' + newEntries.map(entry => {\n    const stringified = JSON.stringify(entry);\n    const hash = hashEntry(stringified);\n    return `${hash}\\t${stringified}`;\n  }).join('\\n');\n\n  const setup = async () => {\n    const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix);\n    await fixOwner.mkdirfix(cache, path.dirname(target));\n    return {\n      target,\n      moved: false\n    };\n  };\n\n  const teardown = async tmp => {\n    if (!tmp.moved) {\n      return rimraf(tmp.target);\n    }\n  };\n\n  const write = async tmp => {\n    await fs.writeFile(tmp.target, newIndex, {\n      flag: 'wx'\n    });\n    await fixOwner.mkdirfix(cache, path.dirname(bucket)); // we use @npmcli/move-file directly here because we\n    // want to overwrite the existing file\n\n    await moveFile(tmp.target, bucket);\n    tmp.moved = true;\n\n    try {\n      await fixOwner.chownr(cache, bucket);\n    } catch (err) {\n      if (err.code !== 'ENOENT') {\n        throw err;\n      }\n    }\n  }; // write the file atomically\n\n\n  const tmp = await setup();\n\n  try {\n    await write(tmp);\n  } finally {\n    await teardown(tmp);\n  } // we reverse the list we generated such that the newest\n  // entries come first in order to make looping through them easier\n  // the true passed to formatEntry tells it to keep null\n  // integrity values, if they made it this far it's because\n  // validateEntry returned true, and as such we should return it\n\n\n  return newEntries.reverse().map(entry => formatEntry(cache, entry, true));\n}\n\nmodule.exports.insert = insert;\n\nasync function insert(cache, key, integrity) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n\n  try {\n    await fixOwner.mkdirfix(cache, path.dirname(bucket));\n    const stringified = JSON.stringify(entry); // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with\n    // this.\n\n    await fs.appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n    await fixOwner.chownr(cache, bucket);\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return undefined;\n    }\n\n    throw err; // There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }\n\n  return formatEntry(cache, entry);\n}\n\nmodule.exports.insert.sync = insertSync;\n\nfunction insertSync(cache, key, integrity) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket));\n  const stringified = JSON.stringify(entry);\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n\n  try {\n    fixOwner.chownr.sync(cache, bucket);\n  } catch (err) {\n    if (err.code !== 'ENOENT') {\n      throw err;\n    }\n  }\n\n  return formatEntry(cache, entry);\n}\n\nmodule.exports.find = find;\n\nasync function find(cache, key) {\n  const bucket = bucketPath(cache, key);\n\n  try {\n    const entries = await bucketEntries(bucket);\n    return entries.reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next);\n      } else {\n        return latest;\n      }\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null;\n    } else {\n      throw err;\n    }\n  }\n}\n\nmodule.exports.find.sync = findSync;\n\nfunction findSync(cache, key) {\n  const bucket = bucketPath(cache, key);\n\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next);\n      } else {\n        return latest;\n      }\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null;\n    } else {\n      throw err;\n    }\n  }\n}\n\nmodule.exports.delete = del;\n\nfunction del(cache, key) {\n  let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n\n  if (!opts.removeFully) {\n    return insert(cache, key, null, opts);\n  }\n\n  const bucket = bucketPath(cache, key);\n  return rimraf(bucket);\n}\n\nmodule.exports.delete.sync = delSync;\n\nfunction delSync(cache, key) {\n  let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n\n  if (!opts.removeFully) {\n    return insertSync(cache, key, null, opts);\n  }\n\n  const bucket = bucketPath(cache, key);\n  return rimraf.sync(bucket);\n}\n\nmodule.exports.lsStream = lsStream;\n\nfunction lsStream(cache) {\n  const indexDir = bucketDir(cache);\n  const stream = new Minipass({\n    objectMode: true\n  }); // Set all this up to run on the stream and then just return the stream\n\n  Promise.resolve().then(async () => {\n    const buckets = await readdirOrEmpty(indexDir);\n    await Promise.all(buckets.map(async bucket => {\n      const bucketPath = path.join(indexDir, bucket);\n      const subbuckets = await readdirOrEmpty(bucketPath);\n      await Promise.all(subbuckets.map(async subbucket => {\n        const subbucketPath = path.join(bucketPath, subbucket); // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n\n        const subbucketEntries = await readdirOrEmpty(subbucketPath);\n        await Promise.all(subbucketEntries.map(async entry => {\n          const entryPath = path.join(subbucketPath, entry);\n\n          try {\n            const entries = await bucketEntries(entryPath); // using a Map here prevents duplicate keys from showing up\n            // twice, I guess?\n\n            const reduced = entries.reduce((acc, entry) => {\n              acc.set(entry.key, entry);\n              return acc;\n            }, new Map()); // reduced is a map of key => entry\n\n            for (const entry of reduced.values()) {\n              const formatted = formatEntry(cache, entry);\n\n              if (formatted) {\n                stream.write(formatted);\n              }\n            }\n          } catch (err) {\n            if (err.code === 'ENOENT') {\n              return undefined;\n            }\n\n            throw err;\n          }\n        }));\n      }));\n    }));\n    stream.end();\n  }).catch(err => stream.emit('error', err));\n  return stream;\n}\n\nmodule.exports.ls = ls;\n\nasync function ls(cache) {\n  const entries = await lsStream(cache).collect();\n  return entries.reduce((acc, xs) => {\n    acc[xs.key] = xs;\n    return acc;\n  }, {});\n}\n\nmodule.exports.bucketEntries = bucketEntries;\n\nasync function bucketEntries(bucket, filter) {\n  const data = await fs.readFile(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\n\nmodule.exports.bucketEntries.sync = bucketEntriesSync;\n\nfunction bucketEntriesSync(bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\n\nfunction _bucketEntries(data, filter) {\n  const entries = [];\n  data.split('\\n').forEach(entry => {\n    if (!entry) {\n      return;\n    }\n\n    const pieces = entry.split('\\t');\n\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return;\n    }\n\n    let obj;\n\n    try {\n      obj = JSON.parse(pieces[1]);\n    } catch (e) {\n      // Entry is corrupted!\n      return;\n    }\n\n    if (obj) {\n      entries.push(obj);\n    }\n  });\n  return entries;\n}\n\nmodule.exports.bucketDir = bucketDir;\n\nfunction bucketDir(cache) {\n  return path.join(cache, `index-v${indexV}`);\n}\n\nmodule.exports.bucketPath = bucketPath;\n\nfunction bucketPath(cache, key) {\n  const hashed = hashKey(key);\n  return path.join.apply(path, [bucketDir(cache)].concat(hashToSegments(hashed)));\n}\n\nmodule.exports.hashKey = hashKey;\n\nfunction hashKey(key) {\n  return hash(key, 'sha256');\n}\n\nmodule.exports.hashEntry = hashEntry;\n\nfunction hashEntry(str) {\n  return hash(str, 'sha1');\n}\n\nfunction hash(str, digest) {\n  return crypto.createHash(digest).update(str).digest('hex');\n}\n\nfunction formatEntry(cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll) {\n    return null;\n  }\n\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata\n  };\n}\n\nfunction readdirOrEmpty(dir) {\n  return fs.readdir(dir).catch(err => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR') {\n      return [];\n    }\n\n    throw err;\n  });\n}","map":{"version":3,"names":["util","require","crypto","fs","Minipass","path","ssri","uniqueFilename","contentPath","fixOwner","hashToSegments","indexV","index","moveFile","_rimraf","rimraf","promisify","sync","module","exports","NotFoundError","Error","constructor","cache","key","code","compact","matchFn","opts","bucket","bucketPath","entries","bucketEntries","newEntries","i","length","entry","integrity","validateEntry","find","oldEntry","unshift","newIndex","map","stringified","JSON","stringify","hash","hashEntry","join","setup","target","tmpPrefix","mkdirfix","dirname","moved","teardown","tmp","write","writeFile","flag","chownr","err","reverse","formatEntry","insert","metadata","size","time","Date","now","appendFile","undefined","insertSync","appendFileSync","reduce","latest","next","findSync","bucketEntriesSync","delete","del","removeFully","delSync","lsStream","indexDir","bucketDir","stream","objectMode","Promise","resolve","then","buckets","readdirOrEmpty","all","subbuckets","subbucket","subbucketPath","subbucketEntries","entryPath","reduced","acc","set","Map","values","formatted","end","catch","emit","ls","collect","xs","filter","data","readFile","_bucketEntries","readFileSync","split","forEach","pieces","obj","parse","e","push","hashed","hashKey","apply","concat","str","digest","createHash","update","keepAll","dir","readdir"],"sources":["/Users/chelsea/Documents/0_AllCoding/shoppingstories-v3/node_modules/npm/node_modules/cacache/lib/entry-index.js"],"sourcesContent":["'use strict'\n\nconst util = require('util')\nconst crypto = require('crypto')\nconst fs = require('@npmcli/fs')\nconst Minipass = require('minipass')\nconst path = require('path')\nconst ssri = require('ssri')\nconst uniqueFilename = require('unique-filename')\n\nconst contentPath = require('./content/path')\nconst fixOwner = require('./util/fix-owner')\nconst hashToSegments = require('./util/hash-to-segments')\nconst indexV = require('../package.json')['cache-version'].index\nconst moveFile = require('@npmcli/move-file')\nconst _rimraf = require('rimraf')\nconst rimraf = util.promisify(_rimraf)\nrimraf.sync = _rimraf.sync\n\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor (cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`)\n    this.code = 'ENOENT'\n    this.cache = cache\n    this.key = key\n  }\n}\n\nmodule.exports.compact = compact\n\nasync function compact (cache, key, matchFn, opts = {}) {\n  const bucket = bucketPath(cache, key)\n  const entries = await bucketEntries(bucket)\n  const newEntries = []\n  // we loop backwards because the bottom-most result is the newest\n  // since we add new entries with appendFile\n  for (let i = entries.length - 1; i >= 0; --i) {\n    const entry = entries[i]\n    // a null integrity could mean either a delete was appended\n    // or the user has simply stored an index that does not map\n    // to any content. we determine if the user wants to keep the\n    // null integrity based on the validateEntry function passed in options.\n    // if the integrity is null and no validateEntry is provided, we break\n    // as we consider the null integrity to be a deletion of everything\n    // that came before it.\n    if (entry.integrity === null && !opts.validateEntry) {\n      break\n    }\n\n    // if this entry is valid, and it is either the first entry or\n    // the newEntries array doesn't already include an entry that\n    // matches this one based on the provided matchFn, then we add\n    // it to the beginning of our list\n    if ((!opts.validateEntry || opts.validateEntry(entry) === true) &&\n      (newEntries.length === 0 ||\n        !newEntries.find((oldEntry) => matchFn(oldEntry, entry)))) {\n      newEntries.unshift(entry)\n    }\n  }\n\n  const newIndex = '\\n' + newEntries.map((entry) => {\n    const stringified = JSON.stringify(entry)\n    const hash = hashEntry(stringified)\n    return `${hash}\\t${stringified}`\n  }).join('\\n')\n\n  const setup = async () => {\n    const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix)\n    await fixOwner.mkdirfix(cache, path.dirname(target))\n    return {\n      target,\n      moved: false,\n    }\n  }\n\n  const teardown = async (tmp) => {\n    if (!tmp.moved) {\n      return rimraf(tmp.target)\n    }\n  }\n\n  const write = async (tmp) => {\n    await fs.writeFile(tmp.target, newIndex, { flag: 'wx' })\n    await fixOwner.mkdirfix(cache, path.dirname(bucket))\n    // we use @npmcli/move-file directly here because we\n    // want to overwrite the existing file\n    await moveFile(tmp.target, bucket)\n    tmp.moved = true\n    try {\n      await fixOwner.chownr(cache, bucket)\n    } catch (err) {\n      if (err.code !== 'ENOENT') {\n        throw err\n      }\n    }\n  }\n\n  // write the file atomically\n  const tmp = await setup()\n  try {\n    await write(tmp)\n  } finally {\n    await teardown(tmp)\n  }\n\n  // we reverse the list we generated such that the newest\n  // entries come first in order to make looping through them easier\n  // the true passed to formatEntry tells it to keep null\n  // integrity values, if they made it this far it's because\n  // validateEntry returned true, and as such we should return it\n  return newEntries.reverse().map((entry) => formatEntry(cache, entry, true))\n}\n\nmodule.exports.insert = insert\n\nasync function insert (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  try {\n    await fixOwner.mkdirfix(cache, path.dirname(bucket))\n    const stringified = JSON.stringify(entry)\n    // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with\n    // this.\n    await fs.appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n    await fixOwner.chownr(cache, bucket)\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return undefined\n    }\n\n    throw err\n    // There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }\n  return formatEntry(cache, entry)\n}\n\nmodule.exports.insert.sync = insertSync\n\nfunction insertSync (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket))\n  const stringified = JSON.stringify(entry)\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n  try {\n    fixOwner.chownr.sync(cache, bucket)\n  } catch (err) {\n    if (err.code !== 'ENOENT') {\n      throw err\n    }\n  }\n  return formatEntry(cache, entry)\n}\n\nmodule.exports.find = find\n\nasync function find (cache, key) {\n  const bucket = bucketPath(cache, key)\n  try {\n    const entries = await bucketEntries(bucket)\n    return entries.reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next)\n      } else {\n        return latest\n      }\n    }, null)\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null\n    } else {\n      throw err\n    }\n  }\n}\n\nmodule.exports.find.sync = findSync\n\nfunction findSync (cache, key) {\n  const bucket = bucketPath(cache, key)\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key) {\n        return formatEntry(cache, next)\n      } else {\n        return latest\n      }\n    }, null)\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null\n    } else {\n      throw err\n    }\n  }\n}\n\nmodule.exports.delete = del\n\nfunction del (cache, key, opts = {}) {\n  if (!opts.removeFully) {\n    return insert(cache, key, null, opts)\n  }\n\n  const bucket = bucketPath(cache, key)\n  return rimraf(bucket)\n}\n\nmodule.exports.delete.sync = delSync\n\nfunction delSync (cache, key, opts = {}) {\n  if (!opts.removeFully) {\n    return insertSync(cache, key, null, opts)\n  }\n\n  const bucket = bucketPath(cache, key)\n  return rimraf.sync(bucket)\n}\n\nmodule.exports.lsStream = lsStream\n\nfunction lsStream (cache) {\n  const indexDir = bucketDir(cache)\n  const stream = new Minipass({ objectMode: true })\n\n  // Set all this up to run on the stream and then just return the stream\n  Promise.resolve().then(async () => {\n    const buckets = await readdirOrEmpty(indexDir)\n    await Promise.all(buckets.map(async (bucket) => {\n      const bucketPath = path.join(indexDir, bucket)\n      const subbuckets = await readdirOrEmpty(bucketPath)\n      await Promise.all(subbuckets.map(async (subbucket) => {\n        const subbucketPath = path.join(bucketPath, subbucket)\n\n        // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n        const subbucketEntries = await readdirOrEmpty(subbucketPath)\n        await Promise.all(subbucketEntries.map(async (entry) => {\n          const entryPath = path.join(subbucketPath, entry)\n          try {\n            const entries = await bucketEntries(entryPath)\n            // using a Map here prevents duplicate keys from showing up\n            // twice, I guess?\n            const reduced = entries.reduce((acc, entry) => {\n              acc.set(entry.key, entry)\n              return acc\n            }, new Map())\n            // reduced is a map of key => entry\n            for (const entry of reduced.values()) {\n              const formatted = formatEntry(cache, entry)\n              if (formatted) {\n                stream.write(formatted)\n              }\n            }\n          } catch (err) {\n            if (err.code === 'ENOENT') {\n              return undefined\n            }\n            throw err\n          }\n        }))\n      }))\n    }))\n    stream.end()\n  }).catch(err => stream.emit('error', err))\n\n  return stream\n}\n\nmodule.exports.ls = ls\n\nasync function ls (cache) {\n  const entries = await lsStream(cache).collect()\n  return entries.reduce((acc, xs) => {\n    acc[xs.key] = xs\n    return acc\n  }, {})\n}\n\nmodule.exports.bucketEntries = bucketEntries\n\nasync function bucketEntries (bucket, filter) {\n  const data = await fs.readFile(bucket, 'utf8')\n  return _bucketEntries(data, filter)\n}\n\nmodule.exports.bucketEntries.sync = bucketEntriesSync\n\nfunction bucketEntriesSync (bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8')\n  return _bucketEntries(data, filter)\n}\n\nfunction _bucketEntries (data, filter) {\n  const entries = []\n  data.split('\\n').forEach((entry) => {\n    if (!entry) {\n      return\n    }\n\n    const pieces = entry.split('\\t')\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return\n    }\n    let obj\n    try {\n      obj = JSON.parse(pieces[1])\n    } catch (e) {\n      // Entry is corrupted!\n      return\n    }\n    if (obj) {\n      entries.push(obj)\n    }\n  })\n  return entries\n}\n\nmodule.exports.bucketDir = bucketDir\n\nfunction bucketDir (cache) {\n  return path.join(cache, `index-v${indexV}`)\n}\n\nmodule.exports.bucketPath = bucketPath\n\nfunction bucketPath (cache, key) {\n  const hashed = hashKey(key)\n  return path.join.apply(\n    path,\n    [bucketDir(cache)].concat(hashToSegments(hashed))\n  )\n}\n\nmodule.exports.hashKey = hashKey\n\nfunction hashKey (key) {\n  return hash(key, 'sha256')\n}\n\nmodule.exports.hashEntry = hashEntry\n\nfunction hashEntry (str) {\n  return hash(str, 'sha1')\n}\n\nfunction hash (str, digest) {\n  return crypto\n    .createHash(digest)\n    .update(str)\n    .digest('hex')\n}\n\nfunction formatEntry (cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll) {\n    return null\n  }\n\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata,\n  }\n}\n\nfunction readdirOrEmpty (dir) {\n  return fs.readdir(dir).catch((err) => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR') {\n      return []\n    }\n\n    throw err\n  })\n}\n"],"mappings":"AAAA;;AAEA,MAAMA,IAAI,GAAGC,OAAO,CAAC,MAAD,CAApB;;AACA,MAAMC,MAAM,GAAGD,OAAO,CAAC,QAAD,CAAtB;;AACA,MAAME,EAAE,GAAGF,OAAO,CAAC,YAAD,CAAlB;;AACA,MAAMG,QAAQ,GAAGH,OAAO,CAAC,UAAD,CAAxB;;AACA,MAAMI,IAAI,GAAGJ,OAAO,CAAC,MAAD,CAApB;;AACA,MAAMK,IAAI,GAAGL,OAAO,CAAC,MAAD,CAApB;;AACA,MAAMM,cAAc,GAAGN,OAAO,CAAC,iBAAD,CAA9B;;AAEA,MAAMO,WAAW,GAAGP,OAAO,CAAC,gBAAD,CAA3B;;AACA,MAAMQ,QAAQ,GAAGR,OAAO,CAAC,kBAAD,CAAxB;;AACA,MAAMS,cAAc,GAAGT,OAAO,CAAC,yBAAD,CAA9B;;AACA,MAAMU,MAAM,GAAGV,OAAO,CAAC,iBAAD,CAAP,CAA2B,eAA3B,EAA4CW,KAA3D;;AACA,MAAMC,QAAQ,GAAGZ,OAAO,CAAC,mBAAD,CAAxB;;AACA,MAAMa,OAAO,GAAGb,OAAO,CAAC,QAAD,CAAvB;;AACA,MAAMc,MAAM,GAAGf,IAAI,CAACgB,SAAL,CAAeF,OAAf,CAAf;AACAC,MAAM,CAACE,IAAP,GAAcH,OAAO,CAACG,IAAtB;AAEAC,MAAM,CAACC,OAAP,CAAeC,aAAf,GAA+B,MAAMA,aAAN,SAA4BC,KAA5B,CAAkC;EAC/DC,WAAW,CAAEC,KAAF,EAASC,GAAT,EAAc;IACvB,MAAO,sBAAqBA,GAAI,aAAYD,KAAM,EAAlD;IACA,KAAKE,IAAL,GAAY,QAAZ;IACA,KAAKF,KAAL,GAAaA,KAAb;IACA,KAAKC,GAAL,GAAWA,GAAX;EACD;;AAN8D,CAAjE;AASAN,MAAM,CAACC,OAAP,CAAeO,OAAf,GAAyBA,OAAzB;;AAEA,eAAeA,OAAf,CAAwBH,KAAxB,EAA+BC,GAA/B,EAAoCG,OAApC,EAAwD;EAAA,IAAXC,IAAW,uEAAJ,EAAI;EACtD,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;EACA,MAAMO,OAAO,GAAG,MAAMC,aAAa,CAACH,MAAD,CAAnC;EACA,MAAMI,UAAU,GAAG,EAAnB,CAHsD,CAItD;EACA;;EACA,KAAK,IAAIC,CAAC,GAAGH,OAAO,CAACI,MAAR,GAAiB,CAA9B,EAAiCD,CAAC,IAAI,CAAtC,EAAyC,EAAEA,CAA3C,EAA8C;IAC5C,MAAME,KAAK,GAAGL,OAAO,CAACG,CAAD,CAArB,CAD4C,CAE5C;IACA;IACA;IACA;IACA;IACA;IACA;;IACA,IAAIE,KAAK,CAACC,SAAN,KAAoB,IAApB,IAA4B,CAACT,IAAI,CAACU,aAAtC,EAAqD;MACnD;IACD,CAX2C,CAa5C;IACA;IACA;IACA;;;IACA,IAAI,CAAC,CAACV,IAAI,CAACU,aAAN,IAAuBV,IAAI,CAACU,aAAL,CAAmBF,KAAnB,MAA8B,IAAtD,MACDH,UAAU,CAACE,MAAX,KAAsB,CAAtB,IACC,CAACF,UAAU,CAACM,IAAX,CAAiBC,QAAD,IAAcb,OAAO,CAACa,QAAD,EAAWJ,KAAX,CAArC,CAFD,CAAJ,EAE+D;MAC7DH,UAAU,CAACQ,OAAX,CAAmBL,KAAnB;IACD;EACF;;EAED,MAAMM,QAAQ,GAAG,OAAOT,UAAU,CAACU,GAAX,CAAgBP,KAAD,IAAW;IAChD,MAAMQ,WAAW,GAAGC,IAAI,CAACC,SAAL,CAAeV,KAAf,CAApB;IACA,MAAMW,IAAI,GAAGC,SAAS,CAACJ,WAAD,CAAtB;IACA,OAAQ,GAAEG,IAAK,KAAIH,WAAY,EAA/B;EACD,CAJuB,EAIrBK,IAJqB,CAIhB,IAJgB,CAAxB;;EAMA,MAAMC,KAAK,GAAG,YAAY;IACxB,MAAMC,MAAM,GAAG5C,cAAc,CAACF,IAAI,CAAC4C,IAAL,CAAU1B,KAAV,EAAiB,KAAjB,CAAD,EAA0BK,IAAI,CAACwB,SAA/B,CAA7B;IACA,MAAM3C,QAAQ,CAAC4C,QAAT,CAAkB9B,KAAlB,EAAyBlB,IAAI,CAACiD,OAAL,CAAaH,MAAb,CAAzB,CAAN;IACA,OAAO;MACLA,MADK;MAELI,KAAK,EAAE;IAFF,CAAP;EAID,CAPD;;EASA,MAAMC,QAAQ,GAAG,MAAOC,GAAP,IAAe;IAC9B,IAAI,CAACA,GAAG,CAACF,KAAT,EAAgB;MACd,OAAOxC,MAAM,CAAC0C,GAAG,CAACN,MAAL,CAAb;IACD;EACF,CAJD;;EAMA,MAAMO,KAAK,GAAG,MAAOD,GAAP,IAAe;IAC3B,MAAMtD,EAAE,CAACwD,SAAH,CAAaF,GAAG,CAACN,MAAjB,EAAyBT,QAAzB,EAAmC;MAAEkB,IAAI,EAAE;IAAR,CAAnC,CAAN;IACA,MAAMnD,QAAQ,CAAC4C,QAAT,CAAkB9B,KAAlB,EAAyBlB,IAAI,CAACiD,OAAL,CAAazB,MAAb,CAAzB,CAAN,CAF2B,CAG3B;IACA;;IACA,MAAMhB,QAAQ,CAAC4C,GAAG,CAACN,MAAL,EAAatB,MAAb,CAAd;IACA4B,GAAG,CAACF,KAAJ,GAAY,IAAZ;;IACA,IAAI;MACF,MAAM9C,QAAQ,CAACoD,MAAT,CAAgBtC,KAAhB,EAAuBM,MAAvB,CAAN;IACD,CAFD,CAEE,OAAOiC,GAAP,EAAY;MACZ,IAAIA,GAAG,CAACrC,IAAJ,KAAa,QAAjB,EAA2B;QACzB,MAAMqC,GAAN;MACD;IACF;EACF,CAdD,CAnDsD,CAmEtD;;;EACA,MAAML,GAAG,GAAG,MAAMP,KAAK,EAAvB;;EACA,IAAI;IACF,MAAMQ,KAAK,CAACD,GAAD,CAAX;EACD,CAFD,SAEU;IACR,MAAMD,QAAQ,CAACC,GAAD,CAAd;EACD,CAzEqD,CA2EtD;EACA;EACA;EACA;EACA;;;EACA,OAAOxB,UAAU,CAAC8B,OAAX,GAAqBpB,GAArB,CAA0BP,KAAD,IAAW4B,WAAW,CAACzC,KAAD,EAAQa,KAAR,EAAe,IAAf,CAA/C,CAAP;AACD;;AAEDlB,MAAM,CAACC,OAAP,CAAe8C,MAAf,GAAwBA,MAAxB;;AAEA,eAAeA,MAAf,CAAuB1C,KAAvB,EAA8BC,GAA9B,EAAmCa,SAAnC,EAAyD;EAAA,IAAXT,IAAW,uEAAJ,EAAI;EACvD,MAAM;IAAEsC,QAAF;IAAYC;EAAZ,IAAqBvC,IAA3B;EACA,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;EACA,MAAMY,KAAK,GAAG;IACZZ,GADY;IAEZa,SAAS,EAAEA,SAAS,IAAI/B,IAAI,CAACwC,SAAL,CAAeT,SAAf,CAFZ;IAGZ+B,IAAI,EAAEC,IAAI,CAACC,GAAL,EAHM;IAIZH,IAJY;IAKZD;EALY,CAAd;;EAOA,IAAI;IACF,MAAMzD,QAAQ,CAAC4C,QAAT,CAAkB9B,KAAlB,EAAyBlB,IAAI,CAACiD,OAAL,CAAazB,MAAb,CAAzB,CAAN;IACA,MAAMe,WAAW,GAAGC,IAAI,CAACC,SAAL,CAAeV,KAAf,CAApB,CAFE,CAGF;IACA;IACA;IACA;IACA;IACA;IACA;IACA;;IACA,MAAMjC,EAAE,CAACoE,UAAH,CAAc1C,MAAd,EAAuB,KAAImB,SAAS,CAACJ,WAAD,CAAc,KAAIA,WAAY,EAAlE,CAAN;IACA,MAAMnC,QAAQ,CAACoD,MAAT,CAAgBtC,KAAhB,EAAuBM,MAAvB,CAAN;EACD,CAbD,CAaE,OAAOiC,GAAP,EAAY;IACZ,IAAIA,GAAG,CAACrC,IAAJ,KAAa,QAAjB,EAA2B;MACzB,OAAO+C,SAAP;IACD;;IAED,MAAMV,GAAN,CALY,CAMZ;IACA;IACA;IACA;IACA;EACD;;EACD,OAAOE,WAAW,CAACzC,KAAD,EAAQa,KAAR,CAAlB;AACD;;AAEDlB,MAAM,CAACC,OAAP,CAAe8C,MAAf,CAAsBhD,IAAtB,GAA6BwD,UAA7B;;AAEA,SAASA,UAAT,CAAqBlD,KAArB,EAA4BC,GAA5B,EAAiCa,SAAjC,EAAuD;EAAA,IAAXT,IAAW,uEAAJ,EAAI;EACrD,MAAM;IAAEsC,QAAF;IAAYC;EAAZ,IAAqBvC,IAA3B;EACA,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;EACA,MAAMY,KAAK,GAAG;IACZZ,GADY;IAEZa,SAAS,EAAEA,SAAS,IAAI/B,IAAI,CAACwC,SAAL,CAAeT,SAAf,CAFZ;IAGZ+B,IAAI,EAAEC,IAAI,CAACC,GAAL,EAHM;IAIZH,IAJY;IAKZD;EALY,CAAd;EAOAzD,QAAQ,CAAC4C,QAAT,CAAkBpC,IAAlB,CAAuBM,KAAvB,EAA8BlB,IAAI,CAACiD,OAAL,CAAazB,MAAb,CAA9B;EACA,MAAMe,WAAW,GAAGC,IAAI,CAACC,SAAL,CAAeV,KAAf,CAApB;EACAjC,EAAE,CAACuE,cAAH,CAAkB7C,MAAlB,EAA2B,KAAImB,SAAS,CAACJ,WAAD,CAAc,KAAIA,WAAY,EAAtE;;EACA,IAAI;IACFnC,QAAQ,CAACoD,MAAT,CAAgB5C,IAAhB,CAAqBM,KAArB,EAA4BM,MAA5B;EACD,CAFD,CAEE,OAAOiC,GAAP,EAAY;IACZ,IAAIA,GAAG,CAACrC,IAAJ,KAAa,QAAjB,EAA2B;MACzB,MAAMqC,GAAN;IACD;EACF;;EACD,OAAOE,WAAW,CAACzC,KAAD,EAAQa,KAAR,CAAlB;AACD;;AAEDlB,MAAM,CAACC,OAAP,CAAeoB,IAAf,GAAsBA,IAAtB;;AAEA,eAAeA,IAAf,CAAqBhB,KAArB,EAA4BC,GAA5B,EAAiC;EAC/B,MAAMK,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;;EACA,IAAI;IACF,MAAMO,OAAO,GAAG,MAAMC,aAAa,CAACH,MAAD,CAAnC;IACA,OAAOE,OAAO,CAAC4C,MAAR,CAAe,CAACC,MAAD,EAASC,IAAT,KAAkB;MACtC,IAAIA,IAAI,IAAIA,IAAI,CAACrD,GAAL,KAAaA,GAAzB,EAA8B;QAC5B,OAAOwC,WAAW,CAACzC,KAAD,EAAQsD,IAAR,CAAlB;MACD,CAFD,MAEO;QACL,OAAOD,MAAP;MACD;IACF,CANM,EAMJ,IANI,CAAP;EAOD,CATD,CASE,OAAOd,GAAP,EAAY;IACZ,IAAIA,GAAG,CAACrC,IAAJ,KAAa,QAAjB,EAA2B;MACzB,OAAO,IAAP;IACD,CAFD,MAEO;MACL,MAAMqC,GAAN;IACD;EACF;AACF;;AAED5C,MAAM,CAACC,OAAP,CAAeoB,IAAf,CAAoBtB,IAApB,GAA2B6D,QAA3B;;AAEA,SAASA,QAAT,CAAmBvD,KAAnB,EAA0BC,GAA1B,EAA+B;EAC7B,MAAMK,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;;EACA,IAAI;IACF,OAAOuD,iBAAiB,CAAClD,MAAD,CAAjB,CAA0B8C,MAA1B,CAAiC,CAACC,MAAD,EAASC,IAAT,KAAkB;MACxD,IAAIA,IAAI,IAAIA,IAAI,CAACrD,GAAL,KAAaA,GAAzB,EAA8B;QAC5B,OAAOwC,WAAW,CAACzC,KAAD,EAAQsD,IAAR,CAAlB;MACD,CAFD,MAEO;QACL,OAAOD,MAAP;MACD;IACF,CANM,EAMJ,IANI,CAAP;EAOD,CARD,CAQE,OAAOd,GAAP,EAAY;IACZ,IAAIA,GAAG,CAACrC,IAAJ,KAAa,QAAjB,EAA2B;MACzB,OAAO,IAAP;IACD,CAFD,MAEO;MACL,MAAMqC,GAAN;IACD;EACF;AACF;;AAED5C,MAAM,CAACC,OAAP,CAAe6D,MAAf,GAAwBC,GAAxB;;AAEA,SAASA,GAAT,CAAc1D,KAAd,EAAqBC,GAArB,EAAqC;EAAA,IAAXI,IAAW,uEAAJ,EAAI;;EACnC,IAAI,CAACA,IAAI,CAACsD,WAAV,EAAuB;IACrB,OAAOjB,MAAM,CAAC1C,KAAD,EAAQC,GAAR,EAAa,IAAb,EAAmBI,IAAnB,CAAb;EACD;;EAED,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;EACA,OAAOT,MAAM,CAACc,MAAD,CAAb;AACD;;AAEDX,MAAM,CAACC,OAAP,CAAe6D,MAAf,CAAsB/D,IAAtB,GAA6BkE,OAA7B;;AAEA,SAASA,OAAT,CAAkB5D,KAAlB,EAAyBC,GAAzB,EAAyC;EAAA,IAAXI,IAAW,uEAAJ,EAAI;;EACvC,IAAI,CAACA,IAAI,CAACsD,WAAV,EAAuB;IACrB,OAAOT,UAAU,CAAClD,KAAD,EAAQC,GAAR,EAAa,IAAb,EAAmBI,IAAnB,CAAjB;EACD;;EAED,MAAMC,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;EACA,OAAOT,MAAM,CAACE,IAAP,CAAYY,MAAZ,CAAP;AACD;;AAEDX,MAAM,CAACC,OAAP,CAAeiE,QAAf,GAA0BA,QAA1B;;AAEA,SAASA,QAAT,CAAmB7D,KAAnB,EAA0B;EACxB,MAAM8D,QAAQ,GAAGC,SAAS,CAAC/D,KAAD,CAA1B;EACA,MAAMgE,MAAM,GAAG,IAAInF,QAAJ,CAAa;IAAEoF,UAAU,EAAE;EAAd,CAAb,CAAf,CAFwB,CAIxB;;EACAC,OAAO,CAACC,OAAR,GAAkBC,IAAlB,CAAuB,YAAY;IACjC,MAAMC,OAAO,GAAG,MAAMC,cAAc,CAACR,QAAD,CAApC;IACA,MAAMI,OAAO,CAACK,GAAR,CAAYF,OAAO,CAACjD,GAAR,CAAY,MAAOd,MAAP,IAAkB;MAC9C,MAAMC,UAAU,GAAGzB,IAAI,CAAC4C,IAAL,CAAUoC,QAAV,EAAoBxD,MAApB,CAAnB;MACA,MAAMkE,UAAU,GAAG,MAAMF,cAAc,CAAC/D,UAAD,CAAvC;MACA,MAAM2D,OAAO,CAACK,GAAR,CAAYC,UAAU,CAACpD,GAAX,CAAe,MAAOqD,SAAP,IAAqB;QACpD,MAAMC,aAAa,GAAG5F,IAAI,CAAC4C,IAAL,CAAUnB,UAAV,EAAsBkE,SAAtB,CAAtB,CADoD,CAGpD;;QACA,MAAME,gBAAgB,GAAG,MAAML,cAAc,CAACI,aAAD,CAA7C;QACA,MAAMR,OAAO,CAACK,GAAR,CAAYI,gBAAgB,CAACvD,GAAjB,CAAqB,MAAOP,KAAP,IAAiB;UACtD,MAAM+D,SAAS,GAAG9F,IAAI,CAAC4C,IAAL,CAAUgD,aAAV,EAAyB7D,KAAzB,CAAlB;;UACA,IAAI;YACF,MAAML,OAAO,GAAG,MAAMC,aAAa,CAACmE,SAAD,CAAnC,CADE,CAEF;YACA;;YACA,MAAMC,OAAO,GAAGrE,OAAO,CAAC4C,MAAR,CAAe,CAAC0B,GAAD,EAAMjE,KAAN,KAAgB;cAC7CiE,GAAG,CAACC,GAAJ,CAAQlE,KAAK,CAACZ,GAAd,EAAmBY,KAAnB;cACA,OAAOiE,GAAP;YACD,CAHe,EAGb,IAAIE,GAAJ,EAHa,CAAhB,CAJE,CAQF;;YACA,KAAK,MAAMnE,KAAX,IAAoBgE,OAAO,CAACI,MAAR,EAApB,EAAsC;cACpC,MAAMC,SAAS,GAAGzC,WAAW,CAACzC,KAAD,EAAQa,KAAR,CAA7B;;cACA,IAAIqE,SAAJ,EAAe;gBACblB,MAAM,CAAC7B,KAAP,CAAa+C,SAAb;cACD;YACF;UACF,CAfD,CAeE,OAAO3C,GAAP,EAAY;YACZ,IAAIA,GAAG,CAACrC,IAAJ,KAAa,QAAjB,EAA2B;cACzB,OAAO+C,SAAP;YACD;;YACD,MAAMV,GAAN;UACD;QACF,CAvBiB,CAAZ,CAAN;MAwBD,CA7BiB,CAAZ,CAAN;IA8BD,CAjCiB,CAAZ,CAAN;IAkCAyB,MAAM,CAACmB,GAAP;EACD,CArCD,EAqCGC,KArCH,CAqCS7C,GAAG,IAAIyB,MAAM,CAACqB,IAAP,CAAY,OAAZ,EAAqB9C,GAArB,CArChB;EAuCA,OAAOyB,MAAP;AACD;;AAEDrE,MAAM,CAACC,OAAP,CAAe0F,EAAf,GAAoBA,EAApB;;AAEA,eAAeA,EAAf,CAAmBtF,KAAnB,EAA0B;EACxB,MAAMQ,OAAO,GAAG,MAAMqD,QAAQ,CAAC7D,KAAD,CAAR,CAAgBuF,OAAhB,EAAtB;EACA,OAAO/E,OAAO,CAAC4C,MAAR,CAAe,CAAC0B,GAAD,EAAMU,EAAN,KAAa;IACjCV,GAAG,CAACU,EAAE,CAACvF,GAAJ,CAAH,GAAcuF,EAAd;IACA,OAAOV,GAAP;EACD,CAHM,EAGJ,EAHI,CAAP;AAID;;AAEDnF,MAAM,CAACC,OAAP,CAAea,aAAf,GAA+BA,aAA/B;;AAEA,eAAeA,aAAf,CAA8BH,MAA9B,EAAsCmF,MAAtC,EAA8C;EAC5C,MAAMC,IAAI,GAAG,MAAM9G,EAAE,CAAC+G,QAAH,CAAYrF,MAAZ,EAAoB,MAApB,CAAnB;EACA,OAAOsF,cAAc,CAACF,IAAD,EAAOD,MAAP,CAArB;AACD;;AAED9F,MAAM,CAACC,OAAP,CAAea,aAAf,CAA6Bf,IAA7B,GAAoC8D,iBAApC;;AAEA,SAASA,iBAAT,CAA4BlD,MAA5B,EAAoCmF,MAApC,EAA4C;EAC1C,MAAMC,IAAI,GAAG9G,EAAE,CAACiH,YAAH,CAAgBvF,MAAhB,EAAwB,MAAxB,CAAb;EACA,OAAOsF,cAAc,CAACF,IAAD,EAAOD,MAAP,CAArB;AACD;;AAED,SAASG,cAAT,CAAyBF,IAAzB,EAA+BD,MAA/B,EAAuC;EACrC,MAAMjF,OAAO,GAAG,EAAhB;EACAkF,IAAI,CAACI,KAAL,CAAW,IAAX,EAAiBC,OAAjB,CAA0BlF,KAAD,IAAW;IAClC,IAAI,CAACA,KAAL,EAAY;MACV;IACD;;IAED,MAAMmF,MAAM,GAAGnF,KAAK,CAACiF,KAAN,CAAY,IAAZ,CAAf;;IACA,IAAI,CAACE,MAAM,CAAC,CAAD,CAAP,IAAcvE,SAAS,CAACuE,MAAM,CAAC,CAAD,CAAP,CAAT,KAAyBA,MAAM,CAAC,CAAD,CAAjD,EAAsD;MACpD;MACA;MACA;IACD;;IACD,IAAIC,GAAJ;;IACA,IAAI;MACFA,GAAG,GAAG3E,IAAI,CAAC4E,KAAL,CAAWF,MAAM,CAAC,CAAD,CAAjB,CAAN;IACD,CAFD,CAEE,OAAOG,CAAP,EAAU;MACV;MACA;IACD;;IACD,IAAIF,GAAJ,EAAS;MACPzF,OAAO,CAAC4F,IAAR,CAAaH,GAAb;IACD;EACF,CArBD;EAsBA,OAAOzF,OAAP;AACD;;AAEDb,MAAM,CAACC,OAAP,CAAemE,SAAf,GAA2BA,SAA3B;;AAEA,SAASA,SAAT,CAAoB/D,KAApB,EAA2B;EACzB,OAAOlB,IAAI,CAAC4C,IAAL,CAAU1B,KAAV,EAAkB,UAASZ,MAAO,EAAlC,CAAP;AACD;;AAEDO,MAAM,CAACC,OAAP,CAAeW,UAAf,GAA4BA,UAA5B;;AAEA,SAASA,UAAT,CAAqBP,KAArB,EAA4BC,GAA5B,EAAiC;EAC/B,MAAMoG,MAAM,GAAGC,OAAO,CAACrG,GAAD,CAAtB;EACA,OAAOnB,IAAI,CAAC4C,IAAL,CAAU6E,KAAV,CACLzH,IADK,EAEL,CAACiF,SAAS,CAAC/D,KAAD,CAAV,EAAmBwG,MAAnB,CAA0BrH,cAAc,CAACkH,MAAD,CAAxC,CAFK,CAAP;AAID;;AAED1G,MAAM,CAACC,OAAP,CAAe0G,OAAf,GAAyBA,OAAzB;;AAEA,SAASA,OAAT,CAAkBrG,GAAlB,EAAuB;EACrB,OAAOuB,IAAI,CAACvB,GAAD,EAAM,QAAN,CAAX;AACD;;AAEDN,MAAM,CAACC,OAAP,CAAe6B,SAAf,GAA2BA,SAA3B;;AAEA,SAASA,SAAT,CAAoBgF,GAApB,EAAyB;EACvB,OAAOjF,IAAI,CAACiF,GAAD,EAAM,MAAN,CAAX;AACD;;AAED,SAASjF,IAAT,CAAeiF,GAAf,EAAoBC,MAApB,EAA4B;EAC1B,OAAO/H,MAAM,CACVgI,UADI,CACOD,MADP,EAEJE,MAFI,CAEGH,GAFH,EAGJC,MAHI,CAGG,KAHH,CAAP;AAID;;AAED,SAASjE,WAAT,CAAsBzC,KAAtB,EAA6Ba,KAA7B,EAAoCgG,OAApC,EAA6C;EAC3C;EACA,IAAI,CAAChG,KAAK,CAACC,SAAP,IAAoB,CAAC+F,OAAzB,EAAkC;IAChC,OAAO,IAAP;EACD;;EAED,OAAO;IACL5G,GAAG,EAAEY,KAAK,CAACZ,GADN;IAELa,SAAS,EAAED,KAAK,CAACC,SAFZ;IAGLhC,IAAI,EAAE+B,KAAK,CAACC,SAAN,GAAkB7B,WAAW,CAACe,KAAD,EAAQa,KAAK,CAACC,SAAd,CAA7B,GAAwDmC,SAHzD;IAILL,IAAI,EAAE/B,KAAK,CAAC+B,IAJP;IAKLC,IAAI,EAAEhC,KAAK,CAACgC,IALP;IAMLF,QAAQ,EAAE9B,KAAK,CAAC8B;EANX,CAAP;AAQD;;AAED,SAAS2B,cAAT,CAAyBwC,GAAzB,EAA8B;EAC5B,OAAOlI,EAAE,CAACmI,OAAH,CAAWD,GAAX,EAAgB1B,KAAhB,CAAuB7C,GAAD,IAAS;IACpC,IAAIA,GAAG,CAACrC,IAAJ,KAAa,QAAb,IAAyBqC,GAAG,CAACrC,IAAJ,KAAa,SAA1C,EAAqD;MACnD,OAAO,EAAP;IACD;;IAED,MAAMqC,GAAN;EACD,CANM,CAAP;AAOD"},"metadata":{},"sourceType":"script"}